{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Portion: Fashion Item Classification\n",
    "\n",
    "* Dataset used: **Fashion MNIST** (28 x 28 grayscale images of fashion items)\n",
    "* Dataset size: 60,000 training samples, 10,000 test samples\n",
    "* Dataset source: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "#### Classification Labels:\n",
    "Label | Description\n",
    ":--- | ---\n",
    "0 | T-shirt/top\n",
    "1 | Trouser\n",
    "2 | Pullover\n",
    "3 | Dress\n",
    "4 | Coat\n",
    "5 | Sandal\n",
    "6 | Shirt\n",
    "7 | Sneaker\n",
    "8 | Bag\n",
    "9 | Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Fashion-MNIST dataset from 'fashion' folder\n",
    "\n",
    "from fashion import mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape is (60000, 784)\n",
      "Input type is <class 'numpy.ndarray'>\n",
      "Labels:\n",
      "[9 0 0 ... 3 0 5]\n",
      "Labels shape is(60000,)\n",
      "Labels type is <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "\n",
    "print(\"Inputs shape is \" + str(X_train.shape)) # 60,000 flattened image vectors (784 pixels long)\n",
    "print(\"Input type is \" + str(type(X_train)))\n",
    "print(\"Labels:\")\n",
    "print(y_train)\n",
    "print(\"Labels shape is\" + str(y_train.shape)) # 60,000 labels\n",
    "print(\"Labels type is \" + str(type(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numerical label to item description\n",
    "\n",
    "def to_description(label):\n",
    "    if label == 0: return \"T-shirt/top\"\n",
    "    elif label == 1: return \"Trouser\"\n",
    "    elif label == 2: return \"Pullover\"\n",
    "    elif label == 3: return \"Dress\"\n",
    "    elif label == 4: return \"Coat\"\n",
    "    elif label == 5: return \"Sandal\"\n",
    "    elif label == 6: return \"Shirt\"\n",
    "    elif label == 7: return \"Sneaker\"\n",
    "    elif label == 8: return \"Bag\"\n",
    "    elif label == 9: return \"Ankle boot\"\n",
    "    else: return \"Label not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  9\n",
      "Description:  Ankle boot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training examples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_sample(sample_num):\n",
    "    flattened_vector = X_train[sample_num] # retrieve flattened vector\n",
    "    image_2d = np.reshape(flattened_vector, (28, 28)) # reshape to 28 x 28 grayscale image array\n",
    "    plt.imshow(image_2d, cmap = plt.get_cmap('gray')) # feed image into matplotlib\n",
    "    print(\"Label: \", y_train[sample_num]) # print actual label\n",
    "    print(\"Description: \", to_description(y_train[sample_num])) # print description\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "visualize_sample(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Pre-Processing\n",
    "1. Normalize the feature vectors/pixel values\n",
    "2. Categorize the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the X_train and X_test dataset pixel values to between 0-1\n",
    "\n",
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0\n",
    "# TODO: fill this in\n",
    "    # Hint: maximum pixel value is still 255\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# TODO: Use Keras to categorize the outputs (\"one-hot\" vectors)\n",
    "    # Use variable names: y_train_categorical, y_test_categorical\n",
    "    # hint: use the to_categorical() keras function to do this for you\n",
    "    \n",
    "y_train_categorical = keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test,num_classes=10)\n",
    "# let's see result of categorizing the output\n",
    "print(y_test_categorical[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create and Compile Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# TODO: fill this in\n",
    "# Feel free to experiment with different number of layers, number of neurons, activation functions, etc.\n",
    "    # Activation functions: https://keras.io/activations/\n",
    "    # Declaring Keras layers: https://keras.io/layers/core/\n",
    "    \n",
    "### Add 1st layer here. Remember that the input_dimension should match up with the input vector dimension!\n",
    "model.add(Dense(units= 500 , input_dim = 784,activation ='relu'))\n",
    "### Add 2nd layer here.\n",
    "model.add(Dense(units=250,activation='relu'))\n",
    "\n",
    "# Add final layer here. Make sure the last layer matches up the output vector dimension\n",
    "    # Hint: use softmax again to output classification probabilities\n",
    "model.add(Dense(units=10,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile model\n",
    "    # Loss: categorical cross-entropy\n",
    "model.compile( optimizer='sgd',loss ='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    # Optimizer: stochastic gradient descent\n",
    "        # Or: experiment with other optimizers? https://keras.io/optimizers/\n",
    "    # Metrics: accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 520,260\n",
      "Trainable params: 520,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from keras_tqdm import TQDMNotebookCallback # TQDM: progress bars\n",
    "from keras.callbacks import TensorBoard # Tensorboard: training plots\n",
    "    \n",
    "# Clear any existing Tensorboard logs\n",
    "import shutil\n",
    "shutil.rmtree('./logs', ignore_errors=True)\n",
    "\n",
    "# Set up callback links to refer back to during training\n",
    "tensorboard = TensorBoard()\n",
    "callbacks_list = [TQDMNotebookCallback(), tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51432 samples, validate on 8568 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fdc86155aa4b17a12156d68b86da44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=51432), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51432/51432 [==============================] - ETA: 5s - loss: 0.5637 - acc: 0.828 - ETA: 3s - loss: 0.5775 - acc: 0.814 - ETA: 3s - loss: 0.5795 - acc: 0.818 - ETA: 2s - loss: 0.5681 - acc: 0.818 - ETA: 2s - loss: 0.5704 - acc: 0.813 - ETA: 2s - loss: 0.5742 - acc: 0.812 - ETA: 2s - loss: 0.5764 - acc: 0.811 - ETA: 2s - loss: 0.5744 - acc: 0.810 - ETA: 2s - loss: 0.5695 - acc: 0.811 - ETA: 2s - loss: 0.5691 - acc: 0.811 - ETA: 2s - loss: 0.5704 - acc: 0.811 - ETA: 2s - loss: 0.5686 - acc: 0.813 - ETA: 2s - loss: 0.5714 - acc: 0.812 - ETA: 2s - loss: 0.5702 - acc: 0.813 - ETA: 1s - loss: 0.5694 - acc: 0.813 - ETA: 1s - loss: 0.5705 - acc: 0.812 - ETA: 1s - loss: 0.5722 - acc: 0.811 - ETA: 1s - loss: 0.5705 - acc: 0.811 - ETA: 1s - loss: 0.5709 - acc: 0.811 - ETA: 1s - loss: 0.5722 - acc: 0.810 - ETA: 1s - loss: 0.5707 - acc: 0.811 - ETA: 1s - loss: 0.5698 - acc: 0.811 - ETA: 1s - loss: 0.5695 - acc: 0.812 - ETA: 1s - loss: 0.5696 - acc: 0.812 - ETA: 1s - loss: 0.5689 - acc: 0.812 - ETA: 1s - loss: 0.5675 - acc: 0.812 - ETA: 1s - loss: 0.5678 - acc: 0.812 - ETA: 1s - loss: 0.5677 - acc: 0.812 - ETA: 1s - loss: 0.5676 - acc: 0.812 - ETA: 1s - loss: 0.5679 - acc: 0.812 - ETA: 1s - loss: 0.5683 - acc: 0.812 - ETA: 0s - loss: 0.5674 - acc: 0.812 - ETA: 0s - loss: 0.5665 - acc: 0.812 - ETA: 0s - loss: 0.5664 - acc: 0.812 - ETA: 0s - loss: 0.5664 - acc: 0.812 - ETA: 0s - loss: 0.5658 - acc: 0.813 - ETA: 0s - loss: 0.5642 - acc: 0.813 - ETA: 0s - loss: 0.5638 - acc: 0.813 - ETA: 0s - loss: 0.5645 - acc: 0.813 - ETA: 0s - loss: 0.5635 - acc: 0.813 - ETA: 0s - loss: 0.5630 - acc: 0.813 - ETA: 0s - loss: 0.5629 - acc: 0.814 - ETA: 0s - loss: 0.5633 - acc: 0.813 - ETA: 0s - loss: 0.5633 - acc: 0.814 - ETA: 0s - loss: 0.5630 - acc: 0.814 - ETA: 0s - loss: 0.5629 - acc: 0.814 - ETA: 0s - loss: 0.5629 - acc: 0.814 - ETA: 0s - loss: 0.5623 - acc: 0.814 - 3s 58us/step - loss: 0.5620 - acc: 0.8145 - val_loss: 0.5538 - val_acc: 0.8144\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=51432), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51432/51432 [==============================] - ETA: 5s - loss: 0.5100 - acc: 0.808 - ETA: 3s - loss: 0.5471 - acc: 0.814 - ETA: 2s - loss: 0.5486 - acc: 0.817 - ETA: 2s - loss: 0.5478 - acc: 0.818 - ETA: 2s - loss: 0.5523 - acc: 0.815 - ETA: 2s - loss: 0.5495 - acc: 0.817 - ETA: 2s - loss: 0.5499 - acc: 0.818 - ETA: 2s - loss: 0.5479 - acc: 0.819 - ETA: 2s - loss: 0.5481 - acc: 0.818 - ETA: 2s - loss: 0.5471 - acc: 0.819 - ETA: 2s - loss: 0.5491 - acc: 0.818 - ETA: 2s - loss: 0.5487 - acc: 0.818 - ETA: 2s - loss: 0.5498 - acc: 0.818 - ETA: 1s - loss: 0.5514 - acc: 0.817 - ETA: 1s - loss: 0.5536 - acc: 0.817 - ETA: 1s - loss: 0.5550 - acc: 0.816 - ETA: 1s - loss: 0.5524 - acc: 0.817 - ETA: 1s - loss: 0.5500 - acc: 0.818 - ETA: 1s - loss: 0.5474 - acc: 0.819 - ETA: 1s - loss: 0.5470 - acc: 0.820 - ETA: 1s - loss: 0.5470 - acc: 0.820 - ETA: 1s - loss: 0.5490 - acc: 0.819 - ETA: 1s - loss: 0.5451 - acc: 0.821 - ETA: 1s - loss: 0.5444 - acc: 0.821 - ETA: 1s - loss: 0.5451 - acc: 0.821 - ETA: 1s - loss: 0.5453 - acc: 0.821 - ETA: 1s - loss: 0.5445 - acc: 0.821 - ETA: 1s - loss: 0.5450 - acc: 0.821 - ETA: 0s - loss: 0.5454 - acc: 0.821 - ETA: 0s - loss: 0.5460 - acc: 0.821 - ETA: 0s - loss: 0.5462 - acc: 0.821 - ETA: 0s - loss: 0.5456 - acc: 0.820 - ETA: 0s - loss: 0.5448 - acc: 0.821 - ETA: 0s - loss: 0.5444 - acc: 0.820 - ETA: 0s - loss: 0.5442 - acc: 0.821 - ETA: 0s - loss: 0.5439 - acc: 0.821 - ETA: 0s - loss: 0.5428 - acc: 0.821 - ETA: 0s - loss: 0.5427 - acc: 0.821 - ETA: 0s - loss: 0.5417 - acc: 0.821 - ETA: 0s - loss: 0.5415 - acc: 0.822 - ETA: 0s - loss: 0.5425 - acc: 0.821 - ETA: 0s - loss: 0.5428 - acc: 0.821 - ETA: 0s - loss: 0.5428 - acc: 0.821 - ETA: 0s - loss: 0.5427 - acc: 0.821 - ETA: 0s - loss: 0.5421 - acc: 0.821 - ETA: 0s - loss: 0.5422 - acc: 0.821 - ETA: 0s - loss: 0.5410 - acc: 0.822 - 3s 56us/step - loss: 0.5416 - acc: 0.8218 - val_loss: 0.5354 - val_acc: 0.8205\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=51432), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51432/51432 [==============================] - ETA: 6s - loss: 0.5076 - acc: 0.825 - ETA: 3s - loss: 0.4902 - acc: 0.844 - ETA: 3s - loss: 0.5061 - acc: 0.835 - ETA: 2s - loss: 0.5202 - acc: 0.830 - ETA: 2s - loss: 0.5227 - acc: 0.827 - ETA: 2s - loss: 0.5361 - acc: 0.822 - ETA: 2s - loss: 0.5363 - acc: 0.823 - ETA: 2s - loss: 0.5307 - acc: 0.824 - ETA: 2s - loss: 0.5318 - acc: 0.824 - ETA: 2s - loss: 0.5335 - acc: 0.822 - ETA: 2s - loss: 0.5318 - acc: 0.822 - ETA: 2s - loss: 0.5345 - acc: 0.821 - ETA: 2s - loss: 0.5350 - acc: 0.821 - ETA: 2s - loss: 0.5315 - acc: 0.822 - ETA: 1s - loss: 0.5302 - acc: 0.823 - ETA: 1s - loss: 0.5276 - acc: 0.823 - ETA: 1s - loss: 0.5280 - acc: 0.823 - ETA: 1s - loss: 0.5252 - acc: 0.824 - ETA: 1s - loss: 0.5257 - acc: 0.824 - ETA: 1s - loss: 0.5244 - acc: 0.825 - ETA: 1s - loss: 0.5240 - acc: 0.826 - ETA: 1s - loss: 0.5276 - acc: 0.825 - ETA: 1s - loss: 0.5285 - acc: 0.824 - ETA: 1s - loss: 0.5299 - acc: 0.824 - ETA: 1s - loss: 0.5296 - acc: 0.824 - ETA: 1s - loss: 0.5294 - acc: 0.824 - ETA: 1s - loss: 0.5294 - acc: 0.824 - ETA: 1s - loss: 0.5300 - acc: 0.824 - ETA: 1s - loss: 0.5289 - acc: 0.825 - ETA: 0s - loss: 0.5291 - acc: 0.824 - ETA: 0s - loss: 0.5288 - acc: 0.824 - ETA: 0s - loss: 0.5282 - acc: 0.824 - ETA: 0s - loss: 0.5295 - acc: 0.824 - ETA: 0s - loss: 0.5304 - acc: 0.823 - ETA: 0s - loss: 0.5283 - acc: 0.824 - ETA: 0s - loss: 0.5280 - acc: 0.824 - ETA: 0s - loss: 0.5281 - acc: 0.824 - ETA: 0s - loss: 0.5277 - acc: 0.824 - ETA: 0s - loss: 0.5274 - acc: 0.824 - ETA: 0s - loss: 0.5273 - acc: 0.824 - ETA: 0s - loss: 0.5273 - acc: 0.824 - ETA: 0s - loss: 0.5282 - acc: 0.824 - ETA: 0s - loss: 0.5274 - acc: 0.824 - ETA: 0s - loss: 0.5265 - acc: 0.824 - ETA: 0s - loss: 0.5254 - acc: 0.825 - ETA: 0s - loss: 0.5257 - acc: 0.824 - 3s 57us/step - loss: 0.5257 - acc: 0.8247 - val_loss: 0.5231 - val_acc: 0.8227\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=51432), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51432/51432 [==============================] - ETA: 6s - loss: 0.5395 - acc: 0.805 - ETA: 3s - loss: 0.5048 - acc: 0.834 - ETA: 3s - loss: 0.5009 - acc: 0.836 - ETA: 2s - loss: 0.5144 - acc: 0.832 - ETA: 2s - loss: 0.5221 - acc: 0.830 - ETA: 2s - loss: 0.5224 - acc: 0.827 - ETA: 2s - loss: 0.5218 - acc: 0.827 - ETA: 2s - loss: 0.5208 - acc: 0.827 - ETA: 2s - loss: 0.5188 - acc: 0.828 - ETA: 2s - loss: 0.5148 - acc: 0.828 - ETA: 2s - loss: 0.5145 - acc: 0.828 - ETA: 2s - loss: 0.5170 - acc: 0.827 - ETA: 2s - loss: 0.5143 - acc: 0.828 - ETA: 2s - loss: 0.5150 - acc: 0.828 - ETA: 1s - loss: 0.5149 - acc: 0.828 - ETA: 1s - loss: 0.5157 - acc: 0.828 - ETA: 1s - loss: 0.5189 - acc: 0.826 - ETA: 1s - loss: 0.5188 - acc: 0.825 - ETA: 1s - loss: 0.5167 - acc: 0.825 - ETA: 1s - loss: 0.5167 - acc: 0.825 - ETA: 1s - loss: 0.5167 - acc: 0.826 - ETA: 1s - loss: 0.5165 - acc: 0.826 - ETA: 1s - loss: 0.5142 - acc: 0.826 - ETA: 1s - loss: 0.5151 - acc: 0.826 - ETA: 1s - loss: 0.5150 - acc: 0.826 - ETA: 1s - loss: 0.5146 - acc: 0.827 - ETA: 1s - loss: 0.5156 - acc: 0.826 - ETA: 1s - loss: 0.5143 - acc: 0.826 - ETA: 1s - loss: 0.5118 - acc: 0.827 - ETA: 1s - loss: 0.5127 - acc: 0.827 - ETA: 1s - loss: 0.5117 - acc: 0.828 - ETA: 0s - loss: 0.5122 - acc: 0.827 - ETA: 0s - loss: 0.5120 - acc: 0.828 - ETA: 0s - loss: 0.5119 - acc: 0.828 - ETA: 0s - loss: 0.5125 - acc: 0.827 - ETA: 0s - loss: 0.5138 - acc: 0.827 - ETA: 0s - loss: 0.5146 - acc: 0.827 - ETA: 0s - loss: 0.5141 - acc: 0.827 - ETA: 0s - loss: 0.5139 - acc: 0.827 - ETA: 0s - loss: 0.5150 - acc: 0.827 - ETA: 0s - loss: 0.5150 - acc: 0.827 - ETA: 0s - loss: 0.5133 - acc: 0.828 - ETA: 0s - loss: 0.5132 - acc: 0.828 - ETA: 0s - loss: 0.5118 - acc: 0.828 - ETA: 0s - loss: 0.5113 - acc: 0.828 - ETA: 0s - loss: 0.5115 - acc: 0.828 - ETA: 0s - loss: 0.5124 - acc: 0.828 - ETA: 0s - loss: 0.5119 - acc: 0.828 - 3s 57us/step - loss: 0.5121 - acc: 0.8287 - val_loss: 0.5192 - val_acc: 0.8206\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=51432), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51432/51432 [==============================] - ETA: 5s - loss: 0.4761 - acc: 0.851 - ETA: 3s - loss: 0.4720 - acc: 0.842 - ETA: 2s - loss: 0.4786 - acc: 0.840 - ETA: 2s - loss: 0.4995 - acc: 0.831 - ETA: 2s - loss: 0.4944 - acc: 0.834 - ETA: 2s - loss: 0.4907 - acc: 0.836 - ETA: 2s - loss: 0.4913 - acc: 0.835 - ETA: 2s - loss: 0.4916 - acc: 0.836 - ETA: 2s - loss: 0.4992 - acc: 0.833 - ETA: 2s - loss: 0.4967 - acc: 0.834 - ETA: 2s - loss: 0.4988 - acc: 0.833 - ETA: 2s - loss: 0.4970 - acc: 0.834 - ETA: 2s - loss: 0.4986 - acc: 0.834 - ETA: 1s - loss: 0.5011 - acc: 0.834 - ETA: 1s - loss: 0.4990 - acc: 0.834 - ETA: 1s - loss: 0.5016 - acc: 0.832 - ETA: 1s - loss: 0.5016 - acc: 0.832 - ETA: 1s - loss: 0.5007 - acc: 0.832 - ETA: 1s - loss: 0.5017 - acc: 0.832 - ETA: 1s - loss: 0.5016 - acc: 0.833 - ETA: 1s - loss: 0.5024 - acc: 0.832 - ETA: 1s - loss: 0.5017 - acc: 0.832 - ETA: 1s - loss: 0.5012 - acc: 0.832 - ETA: 1s - loss: 0.5018 - acc: 0.832 - ETA: 1s - loss: 0.5025 - acc: 0.831 - ETA: 1s - loss: 0.5031 - acc: 0.831 - ETA: 1s - loss: 0.5024 - acc: 0.832 - ETA: 1s - loss: 0.5014 - acc: 0.832 - ETA: 1s - loss: 0.5011 - acc: 0.832 - ETA: 0s - loss: 0.5011 - acc: 0.833 - ETA: 0s - loss: 0.5005 - acc: 0.832 - ETA: 0s - loss: 0.5005 - acc: 0.832 - ETA: 0s - loss: 0.5001 - acc: 0.832 - ETA: 0s - loss: 0.5015 - acc: 0.832 - ETA: 0s - loss: 0.5016 - acc: 0.831 - ETA: 0s - loss: 0.5012 - acc: 0.831 - ETA: 0s - loss: 0.5015 - acc: 0.831 - ETA: 0s - loss: 0.5015 - acc: 0.831 - ETA: 0s - loss: 0.4996 - acc: 0.832 - ETA: 0s - loss: 0.5003 - acc: 0.831 - ETA: 0s - loss: 0.5006 - acc: 0.831 - ETA: 0s - loss: 0.5009 - acc: 0.831 - ETA: 0s - loss: 0.5012 - acc: 0.830 - ETA: 0s - loss: 0.5013 - acc: 0.831 - ETA: 0s - loss: 0.5015 - acc: 0.831 - ETA: 0s - loss: 0.5010 - acc: 0.831 - 3s 57us/step - loss: 0.5009 - acc: 0.8311 - val_loss: 0.5033 - val_acc: 0.8281\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=51432), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51432/51432 [==============================] - ETA: 6s - loss: 0.4818 - acc: 0.845 - ETA: 3s - loss: 0.4936 - acc: 0.834 - ETA: 3s - loss: 0.5047 - acc: 0.828 - ETA: 2s - loss: 0.4883 - acc: 0.832 - ETA: 2s - loss: 0.4942 - acc: 0.830 - ETA: 2s - loss: 0.4963 - acc: 0.830 - ETA: 2s - loss: 0.4995 - acc: 0.831 - ETA: 2s - loss: 0.4957 - acc: 0.831 - ETA: 2s - loss: 0.4990 - acc: 0.829 - ETA: 2s - loss: 0.4948 - acc: 0.833 - ETA: 2s - loss: 0.4914 - acc: 0.834 - ETA: 2s - loss: 0.4942 - acc: 0.833 - ETA: 2s - loss: 0.4918 - acc: 0.834 - ETA: 2s - loss: 0.4958 - acc: 0.834 - ETA: 1s - loss: 0.4952 - acc: 0.834 - ETA: 1s - loss: 0.4951 - acc: 0.833 - ETA: 1s - loss: 0.4935 - acc: 0.833 - ETA: 1s - loss: 0.4945 - acc: 0.832 - ETA: 1s - loss: 0.4964 - acc: 0.832 - ETA: 1s - loss: 0.4952 - acc: 0.833 - ETA: 1s - loss: 0.4971 - acc: 0.832 - ETA: 1s - loss: 0.4983 - acc: 0.832 - ETA: 1s - loss: 0.4959 - acc: 0.833 - ETA: 1s - loss: 0.4959 - acc: 0.833 - ETA: 1s - loss: 0.4953 - acc: 0.834 - ETA: 1s - loss: 0.4937 - acc: 0.835 - ETA: 1s - loss: 0.4942 - acc: 0.834 - ETA: 1s - loss: 0.4941 - acc: 0.834 - ETA: 1s - loss: 0.4945 - acc: 0.833 - ETA: 1s - loss: 0.4958 - acc: 0.833 - ETA: 0s - loss: 0.4953 - acc: 0.834 - ETA: 0s - loss: 0.4939 - acc: 0.835 - ETA: 0s - loss: 0.4941 - acc: 0.835 - ETA: 0s - loss: 0.4935 - acc: 0.835 - ETA: 0s - loss: 0.4926 - acc: 0.835 - ETA: 0s - loss: 0.4931 - acc: 0.835 - ETA: 0s - loss: 0.4913 - acc: 0.836 - ETA: 0s - loss: 0.4928 - acc: 0.835 - ETA: 0s - loss: 0.4922 - acc: 0.836 - ETA: 0s - loss: 0.4920 - acc: 0.836 - ETA: 0s - loss: 0.4923 - acc: 0.835 - ETA: 0s - loss: 0.4915 - acc: 0.835 - ETA: 0s - loss: 0.4911 - acc: 0.836 - ETA: 0s - loss: 0.4904 - acc: 0.836 - ETA: 0s - loss: 0.4905 - acc: 0.836 - ETA: 0s - loss: 0.4904 - acc: 0.836 - ETA: 0s - loss: 0.4906 - acc: 0.836 - 3s 56us/step - loss: 0.4908 - acc: 0.8360 - val_loss: 0.4931 - val_acc: 0.8309\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=51432), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51432/51432 [==============================] - ETA: 5s - loss: 0.4717 - acc: 0.842 - ETA: 3s - loss: 0.4816 - acc: 0.842 - ETA: 2s - loss: 0.4744 - acc: 0.840 - ETA: 2s - loss: 0.4833 - acc: 0.837 - ETA: 2s - loss: 0.4772 - acc: 0.838 - ETA: 2s - loss: 0.4774 - acc: 0.838 - ETA: 2s - loss: 0.4756 - acc: 0.841 - ETA: 2s - loss: 0.4790 - acc: 0.839 - ETA: 2s - loss: 0.4841 - acc: 0.836 - ETA: 2s - loss: 0.4839 - acc: 0.836 - ETA: 2s - loss: 0.4840 - acc: 0.835 - ETA: 2s - loss: 0.4862 - acc: 0.835 - ETA: 1s - loss: 0.4861 - acc: 0.835 - ETA: 1s - loss: 0.4853 - acc: 0.835 - ETA: 1s - loss: 0.4876 - acc: 0.835 - ETA: 1s - loss: 0.4895 - acc: 0.834 - ETA: 1s - loss: 0.4883 - acc: 0.835 - ETA: 1s - loss: 0.4848 - acc: 0.836 - ETA: 1s - loss: 0.4841 - acc: 0.837 - ETA: 1s - loss: 0.4831 - acc: 0.837 - ETA: 1s - loss: 0.4818 - acc: 0.838 - ETA: 1s - loss: 0.4815 - acc: 0.838 - ETA: 1s - loss: 0.4819 - acc: 0.837 - ETA: 1s - loss: 0.4819 - acc: 0.838 - ETA: 1s - loss: 0.4823 - acc: 0.837 - ETA: 1s - loss: 0.4806 - acc: 0.838 - ETA: 1s - loss: 0.4806 - acc: 0.838 - ETA: 1s - loss: 0.4812 - acc: 0.837 - ETA: 1s - loss: 0.4814 - acc: 0.837 - ETA: 1s - loss: 0.4830 - acc: 0.836 - ETA: 0s - loss: 0.4819 - acc: 0.837 - ETA: 0s - loss: 0.4820 - acc: 0.837 - ETA: 0s - loss: 0.4824 - acc: 0.837 - ETA: 0s - loss: 0.4826 - acc: 0.836 - ETA: 0s - loss: 0.4822 - acc: 0.836 - ETA: 0s - loss: 0.4817 - acc: 0.837 - ETA: 0s - loss: 0.4823 - acc: 0.836 - ETA: 0s - loss: 0.4826 - acc: 0.836 - ETA: 0s - loss: 0.4831 - acc: 0.836 - ETA: 0s - loss: 0.4823 - acc: 0.836 - ETA: 0s - loss: 0.4819 - acc: 0.837 - ETA: 0s - loss: 0.4819 - acc: 0.837 - ETA: 0s - loss: 0.4818 - acc: 0.836 - ETA: 0s - loss: 0.4816 - acc: 0.837 - ETA: 0s - loss: 0.4818 - acc: 0.837 - ETA: 0s - loss: 0.4820 - acc: 0.836 - ETA: 0s - loss: 0.4816 - acc: 0.837 - 3s 57us/step - loss: 0.4816 - acc: 0.8369 - val_loss: 0.4858 - val_acc: 0.8313\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x232a13842e8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Fit model to training data\n",
    "    # Reserve some fraction of training data as validation data\n",
    "    # Pick number of epochs\n",
    "    # Pick a batch_size\n",
    "    # Pass in relevant callbacks_list from above\n",
    "model.fit(X_train,y_train_categorical,batch_size=350, epochs=7, validation_split=.1428,callbacks=callbacks_list)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 41us/step\n",
      "[0.5069769051551819, 0.8219]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Evaluate model on test data\n",
    "\n",
    "# Use model.evaluate()\n",
    "# Also: open up the training logs in Tensorboard to check validation_loss for overfitting\n",
    "loss_and_metrics = model.evaluate(X_test, y_test_categorical, batch_size=128)\n",
    "\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final predictions testing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Compare actual class to predicted class\n",
    "def visualize_test_sample(test_sample_num):\n",
    "    \n",
    "    # Display actual image & label\n",
    "    flattened_vector = X_test[test_sample_num] # retrieve flattened vector\n",
    "    image_2d = np.reshape(flattened_vector, (28, 28)) # reshape to 28 x 28 grayscale image array\n",
    "    plt.imshow(image_2d, cmap = plt.get_cmap('gray')) # feed image into matplotlib\n",
    "    print(\"Actual Label: \", y_test[test_sample_num]) # print actual label\n",
    "    print(\"Actual Description: \", to_description(y_test[test_sample_num])) # print description\n",
    "    plt.show()\n",
    "    \n",
    "    # Print predicted label\n",
    "    test_sample = np.expand_dims(X_test[test_sample_num], axis=0) # pick out a one-sample \"batch\" to feed into model\n",
    "    predicted_scores = model.predict(test_sample) # outputted probabilities vector\n",
    "    print(\"Outputted scores: \", predicted_scores) # print predicted scores\n",
    "\n",
    "    predicted_class = np.argmax(predicted_scores) # pick the class with highest probability --> final prediction\n",
    "    print(\"Predicted Label: \", predicted_class) # print predicted classification\n",
    "    print(\"Predicted Description: \", to_description(predicted_class)) # print predicted label description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label:  2\n",
      "Actual Description:  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputted scores:  [[4.2893353e-04 7.0627316e-06 8.7448514e-01 1.5672561e-04 1.2990551e-02\n",
      "  2.7078116e-07 1.1188243e-01 1.0971700e-08 4.8880025e-05 6.1159867e-08]]\n",
      "Predicted Label:  2\n",
      "Predicted Description:  Pullover\n"
     ]
    }
   ],
   "source": [
    "visualize_test_sample(1\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
